{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Lab_03_data1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file data to variable text\n",
    "with open(file_path,'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation marks and quotation marks\n",
    "text = text.translate(str.maketrans('', '', string.punctuation +  \"‘’“”'\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopword Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [token for token in tokens if not token.lower() in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatiztion\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokens = [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tokens back into a string\n",
    "processed_text = ' '.join(tokens)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement TF-IDF model from scratch\n",
    "# Compute document frequencies\n",
    "doc_freq = defaultdict(int)\n",
    "for token in tokens:\n",
    "    doc_freq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute inverse document frequencies\n",
    "num_docs = len(doc_freq)\n",
    "idf = {}\n",
    "for token, freq in doc_freq.items():\n",
    "    idf[token] = math.log(num_docs / (freq + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF weights for each token\n",
    "tf_idf = {}\n",
    "for token in tokens:\n",
    "    tf_idf[token] = (tokens.count(token) / len(tokens)) * idf[token]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tokens by TF-IDF weight:\n",
      "system 0.046525191668186576\n",
      "information 0.04278862693241877\n",
      "energy 0.037546532484194955\n",
      "thermodynamics 0.02900313374368789\n",
      "environment 0.02900313374368789\n",
      "organism 0.025929788661136176\n",
      "one 0.02434181763845234\n",
      "said 0.02434181763845234\n",
      "Business 0.02434181763845234\n",
      "law 0.022715925329262112\n"
     ]
    }
   ],
   "source": [
    "# Print the top 10 tokens by TF-IDF weight\n",
    "sorted_tokens = sorted(tf_idf.items(), key=lambda x: x[1], reverse=True)\n",
    "print('Top 10 tokens by TF-IDF weight:')\n",
    "for token, weight in sorted_tokens[:10]:\n",
    "    print(token, weight)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement TF-IDF model with Scikit-learn package\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "tf_idf_matrix = vectorizer.fit_transform([processed_text])\n",
    "feature_names = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tokens by TF-IDF weight (Scikit-learn):\n",
      "system 0.271883104297442\n",
      "information 0.2621729934296762\n",
      "energy 0.2039123282230815\n",
      "thermodynamics 0.16507188475201834\n",
      "environment 0.15536177388425257\n",
      "life 0.135941552148721\n",
      "entropy 0.1262314412809552\n",
      "one 0.1262314412809552\n",
      "organism 0.1262314412809552\n",
      "business 0.11652133041318942\n"
     ]
    }
   ],
   "source": [
    "# Print the top 10 tokens by TF-IDF weight using Scikit-learn\n",
    "tf_idf_scores = tf_idf_matrix.toarray()[0]\n",
    "sorted_scores = np.argsort(tf_idf_scores)[::-1]\n",
    "print('Top 10 tokens by TF-IDF weight (Scikit-learn):')\n",
    "for index in sorted_scores[:10]:\n",
    "    print(feature_names[index], tf_idf_scores[index])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement K-means clustering on the processed data\n",
    "num_clusters = int(input(\"Enter the number of clusters: \"))\n",
    "kmeans = KMeans(n_clusters=num_clusters,random_state=42)\n",
    "kmeans.fit(tf_idf_matrix)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49313cae04563e702afcd133ffff9d1ab7daa4f19d85edb0f0628b223bec4e78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
